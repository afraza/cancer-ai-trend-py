# Using below prompt, I asked ChatGPT (plus) and Grok (SuperGrok) to get the below ai_term list
# I have split a 300MB text file into ~100 chunks (each chunk is plain text).
# The text is scientific papers about AI in cancer research. Your task is:
# 1. Read each chunk I upload.
# 2. Extract **all Artificial Intelligence–related terms** from the text.
#   - Include (but not limited to) techniques, methods, algorithms, tools, models, neural network architectures, NLP terms, computer vision terms, reinforcement learning terms, and related AI concepts.
#   - Capture synonyms, abbreviations, and variations (e.g., "SVM" and "support vector machine", "CNN" and "convolutional neural network") and save all the synonyms as separate item on a python list for each chunk.
# 3. Deduplicate them within each chunk.
# 4. After I upload all 100 chunks, merge and deduplicate the terms across all chunks into one **final comprehensive list**
ai_terms = [
    "3D U-Net",
    "ablation study",
    "acm",
    "active contour model",
    "adaboost",
    "ai model",
    "ai-assisted model",
    "Artificial Intelligence (AI)",
    "artificial neural network",
    "attention mechanism",
    "Attention-Based Dilated Bridge Net (ADB-Net)",
    "attention-based model",
    "bayesian network",
    "Boltzmann machine",
    "catboost",
    "class activation mapping",
    "classification",
    "clustering",
    "cnn",
    "computer assisted diagnosis",
    "computer assisted tomography",
    "Computer-Aided Diagnosis (CAD / CADx)",
    "Contrastive Transformer",
    "convolution block",
    "Convolutional Neural Network (CNN)",
    "cox regression model",
    "CRF Decoder",
    "crbm",
    "Customized U-Net",
    "data analysis",
    "data mining",
    "data mining algorithms",
    "dbn",
    "decision support systems",
    "decision tree",
    "Deep Belief Network (DBN)",
    "deep convolutional neural network",
    "deep convolutional networks",
    "deep neural network",
    "deep neural network algorithms",
    "Dense Convolutional Network",
    "dice similarity coefficient",
    "dimensionality reduction",
    "disease forecasting models",
    "dnn",
    "Dragonfly Optimization (DFO)",
    "ensemble learning",
    "Explainable Artificial Intelligence (XAI / Explainable AI)",
    "feature extraction",
    "feature importance",
    "feature selection",
    "gamma correction",
    "gan",
    "generative adversarial network",
    "Genetic Algorithm (GA)",
    "GoogLeNet",
    "gradient boosting",
    "Graph Convolutional Neural Network (GCN)",
    "graph learning",
    "Graph Neural Network (GNN)",
    "graph neural network",
    "Graph Transformer",
    "gsea",
    "Hierarchical Refinement Graph Convolutional Neural Network (HRGCN)",
    "hyperparameter optimizer",
    "image analysis",
    "image classification",
    "image enhancement",
    "image processing",
    "image recognition",
    "image reconstruction",
    "image segmentation",
    "image segmentation algorithms",
    "Independent Component Analysis (ICA)",
    "interpretable machine learning",
    "interpretability",
    "Jaya Optimization Algorithm",
    "k nearest neighbor",
    "knn",
    "knowledge graph",
    "lasso regression",
    "learning model",
    "lightgbm",
    "liver cancer prediction",
    "long short term memory",
    "lstm",
    "machine learning",
    "Mask R-CNN",
    "mask rcnn",
    "medical imaging",
    "meta learning",
    "microRNA",
    "mlp",
    "model evaluation",
    "multi-agent systems",
    "multi-modal",
    "multi-modal model",
    "multi-omics",
    "multi-omics analysis",
    "multi-task learning",
    "multimodal",
    "multimodal model",
    "multiple instance learning",
    "naive bayes",
    "Natural Language Processing (NLP)",
    "neuroimaging",
    "nlp",
    "non-invasive",
    "non-local mean filter",
    "object detection",
    "pattern recognition",
    "Pharmacophore Modeling",
    "polyp detection",
    "pre-processing",
    "predictive analytics",
    "predictive biomarkers",
    "predictive model",
    "predictive modeling",
    "predictive performance",
    "principal component analysis",
    "probabilistic model",
    "prognostic model",
    "Quantitative Structure–Activity Relationship (QSAR) models",
    "random forest",
    "random forest classifier",
    "recurrent neural network",
    "regression model",
    "reinforcement learning",
    "representation learning",
    "Residual Network (ResNet, ResNetv2)",
    "residual network",
    "resnetv2",
    "Restricted Boltzmann Machine (RBM / CRBM)",
    "rnn",
    "salient instance inference",
    "Scat Inception Model",
    "self attention",
    "Self-Attention Transformer",
    "self supervised learning",
    "semi supervised learning",
    "sequential feature selection",
    "simulated validation",
    "spatial attention",
    "spatial pyramid pooling",
    "spatial pyramid pooling layer",
    "Sparse Supervised Autoencoder Neural Network (SSAE)",
    "squeeze excitation",
    "squeeze excitation block",
    "structural similarity index",
    "supervised classification",
    "Supervised Learning",
    "supervised learning",
    "Support Vector Machine (SVM)",
    "support vector machine",
    "support vector machine classifier",
    "svm",
    "svm classifier",
    "svm model",
    "SwinV2 Transformer",
    "tcr prediction",
    "transfer learning",
    "Transformer Networks",
    "transformer architecture",
    "u net",
    "u-net",
    "unet",
    "unsupervised learning",
    "VGG16",
    "VGG19",
    "vision transformer",
    "weakly supervised classification",
    "weakly supervised learning",
    "xgboost",
    "xgboost model"
]